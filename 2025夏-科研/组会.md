# ZJU  Daily  数据智能方向  组会

## 每周四晚19点整

----------------------------------------
2025.7.10

研0 首次加入组会
先介绍组会内容：以分享前沿为主 今年agent为主
7位新生 以老研一同学为主力  有分享论文的思路
介绍+讨论大约10min一篇 每周分享5篇左右  也就1H结束
组会上也不问进度 私下沟通
考虑组会如何不沉闷

徐文溢 新研三 请假 多模态 RAG 快手实习
王泽宇 河北 SQL方向
宇翔是直博四年级 多模态等等 
佳晖是直博二年级 在字节实习 文本和SQL相关 宁波本地人
禹 女生 研2 在淘天实习 搜推智能事业部  文章写作和表达很强
怡江 研2 在字节实习 大小模型协同方向
中豪 研2 LLM for检索 在蚂蚁智能引擎实习 多模态检索
陈峥 文本加表格的RAG 华为联合培养
lyc 数据整备数据治理 华为联合培养

沛根 研1 阿里实习 多agent系统 新生接触最多
梦菲 研1 科学文献挖掘 阿里
宇阳 研1 多模态LLM RAG 医疗相关agent 最偏应用 擅长吉他
同旺 研1 智能数据库 字节实习 SQL重写相关工作  多agent经验 比较早

我 研0
丁瑞 研0 本科做过agent
罗万相 研0 
缪婧LJ 研0 也是RAG agent 工作流
齐明杰 研0 科研接触最早
邹慧 研0 毕设相关是llama等
叶章衍 研0 福州人

论文分享 共享屏幕 听汇报
【重点】怎么读论文

制定的论文分析骨架 粗读也要了解
因为一用于思路梳理 二用于锻炼表达【以后的工作也会涉及这样的报告】
论文的选择：7日内arxiv上最新的top论文 个人认为"好"的文章

- title + 一句话总结=把握核心
- what研究内容（领域）
- why研究动机是什么123
- 技术动机123
- how 解决方案：xxx ABC
- 文章整体优势缺点与未来潜力

具体论文 

agentic-R1模型 distilled dual 框架 用来提升复杂数学问题的准确与泛化
老师问答：融合两个模型的"策略轨迹"再distill  agentic的地方在哪

web-sailor 阿里通义千问的工作 核心在构造复杂训练数据 复杂网络检索任务中超人类的推理能力
老师问答：要定义一下标题里的agent是什么  answer怎么构造 怎么确定这个答案
知识图谱 子图 方法是很老的
是否有不用数据驱动的zero-shot方法
这个是数据驱动的工作 那么数据怎么构建是最重要的 文章没说清楚
你觉得是否用R1就可以
什么微调方法 数据量也没讲 全量还是PEFT
文章和其他模型的对比 不一定真实 不是参数越高 效果就直接明显的
比不上deepresearch  但是就说了不能和闭源比
老师建议识别一下阿里的KPI论文 和论文作者
通讯是阿里的周靖人 通义领军人物

codeAgents: a token efficient framework...
用伪代码协议 代替自然语言 在agent之间进行交互和推理流程
优势是token成本低 规范化 高效可拓展
老师问答：模型间的工具调用或通信 很有可能作为范式 代替自然语言 方向很好 形式化语言等
要求经典文章要记录保留  不要遗忘  以便后续文章的分类归纳

EvoAgentX 开源框架  比较工程的一篇文章 自动化生成和优化工作流 提升多agent的效率和性能
架构是简单的5层现有工作的拼接

研0 同学的看法和术语
SFT监督微调   强化学习 DPO

小规模模型的好处：社区生态热闹 数据隐私 响应快成本低  
虽然能力弱 未来可期 况且技术上先发展效果 再优化大小 未来可能小规模效果也很好

----------------------------------------
2025.7.17

老师看重论文的作者身份 辅助判断工作价值

新论文
Aime 框架 计划的动态适应性 ReAct框架 推理 行动 观察的循环 用专有工具主动汇报 字节
评论：是将来的趋势

PyVision  MLLM（多模态）交互式框架  视觉推理系统 agent自己生成tool 自己使用
评论：覆盖的工具的多少 实验的置信度  图像问题会有显著性等主观指标需要超参数设置 无法通过统一pipeline解决 技术亮点的问题

MemAgent 字节 文本压缩问题 通过RL 高效处理任意长度文本 但保持性能不降 现在的压缩总结摘要容易丢失信息
通过RL训练模型 【管理定长可更新的mem】   训练采用DAPO算法
评论：问题 每个任务的压缩算法应该通用 但是本文不是通用的 就没法用普适问题
个人：记忆本来就需要规模效应  就不能靠一个定长的区域加覆盖方法解决所有问题

how to train a leader ，MLPO方法  字节Seed 层次化训练 通过训练一个leader 协调未训练的agent
让leader分析 整合 纠错能力 分层架构
解决成本问题和灵活性
技术方法 两阶段训练 监督微调+多agent引导优化 GRPO损失函数 多轮迭代
老师：认为类似思路文章很多 但是本文只是技术上亮点
个人：与我的通用公司中的人类组织架构想法相关

concordia：EC架构 支持评估、叙事、模拟三大类任务
【每个component组件有四个生命周期钩子函数 observe和act】
engine中有并行 顺序 异步三种调度交互范式
老师：认为文章定义的异步顺序并行 不如一个世界统一的timer一步步做 每步中 世界中不同的agent在做不同的事情即可
个人：与个人想法和目前开发的MAS框架很像 值得读

总之 老师认为目前每周90%的arxiv文章都不值得仔细读 经不起推敲


----------------------------------------
2025.7.24


open source LLMs  SMACS框架 多个开源LLM作为agent的可拓展框架
怎么处理多输出作为最终输出？先验评分（引入历史回答的效果评分）  加上  混合分数去评估响应  最后合成一个响应
实验证明开源的结合在很多公开数据集 能超过1个闭源模型
老师认为这个方法确实简单有效


deep research相关  测试时扩散   即把research报告过程建模成 RAG的扩散过程
文章认为研究报告很像人类写作 从初稿 修订 再写的循环  很像扩散模型的逐步去噪的范式
TTD-DR框架  
老师认为这种多次生成迭代的过程目前代码生成框架已经在用 本文不是真正使用TTD
agent在软件工程中code的角色到底是顶层设计还是底层实现  目前的agent应该只控制在底层实现
老师认为软件开发行业对agent的接受程度比数据库领域高很多


SPAR框架 就是学术文献深层迭代检索
多agent 对每篇文章的引用链的关联拓展  五大智能体 模拟人类进行拓展检索
平衡检索的精确率和召回率
北京的一个机构
老师认为很常见的工作
题外话是arxiv的agent和其下的功能和应用 按照关键词进行爬虫 重新开始写一周文章总结


Decent LLMs的去中心化架构  在节点恶意或出错系统时 实现高效鲁棒地选择高质量回答
有评估agent去评分工作agent  评分算法是几何中值算法 输入评分向量的欧几里得距离之和的min
选择高质量答案  框架过程是用户广播问题  每个工作agent的回答都广播给评分agent
优势是去中心化 未来可以多轮辩论
个人问题 怎么保证评估agent不被影响 且回答本身是否都会变得中庸
老师也是这个问题
题外话：技术动机和解决方案要分开


TinyTroupe 微软  工具包
快速构建人类模拟实验的框架  主打细粒度的人格规范  一体化且精细的流水线 创建 过程验证 结果导出
技术细节是工厂 通过自然语言 批量生成结构化人格 用人格初始化agent
通过可配置步长的时间模拟  统一调度和控制消息交互
而且在运行时通过自然语言 对状态进行验证
有全局叙事和局部事件触发
老师的问题：如果人格不会变化 agents又根据源源不断的事件产生不同的动作
那么为什么要引入人格评分  老师认为系统目的是不断运行从而让act让人格对齐
但文章只有直接拦截act  并没有引导act和人格对齐

研0被提问时间
老师建议看看纯理论的高度看论文


----------------------------------------
2025.7.31

assemble your crew automatic multi-agent...
ARG-DESIGNER模型 自回归图生成范式 从无到有构建多agent的写作拓扑
即修剪冗余连接 增量连接  动态拓展智能体池
潜力即这个范式可拓展 规模化部署
老师问题：实验在什么场景下做？常见的benchmark
并且实验不一定客观
目前的问题是很多基模不同 导致同框架指标在不同论文里也不一样
审慎对待 不一定有大提升
多智能体拓扑可能是目前MAS项目之后的点
PS 多智能体拓扑综述论文 有四大类 是否中心 顺序等结构


GenoMAS 生物的垂域多agent框架
用于端到端基因表达分析
六个Agent 任务可以拆解 基于历史和执行状态自主决策推进跳过回滚
老师问题：实验怎么做 和谁比


一种ARPO算法 优化多轮tool交互的agent的强化学习训练过程
基于熵的自适应采样 平衡了全局采样和步骤采样
老师评价：看熵是做可解释性的典型途径 但是API用不了 要模型倒数几层做


一个多智能体系统中的整合心智理论和结构化批判
就是需要高阶认知任务时 要求的能力有推断他人视角 评审等 提升协作效率和协作的质量
也有四大智能体 专家 评估 协调 整合的agent
这个框架适合高度协同 严谨论证的任务
老师评价：没实验  怎么量化评估  且提前预测他人观点时也需要听他人观点
然后又问论文来源  认为无价值  除非人类模拟 否则agent和人有本质区别

最速组会 47min

----------------------------------------
2025.8.7

SWE-debate框架  软件修复领域的agent  静态代码分析 提取
现有agent的思考：单一视角 缺少比较 多视角分析批判
先根据prompt找入口检索 再往深找 
三轮的辩论  独立提出修改 相互评审批判优化 整合  最终将方法放入MCTS（蒙特卡洛树搜索）
实验上目前生成最优 目前这个SWE榜单比较公正
个人思考 静态方法缺少运行时测试  这个方法比较合理 符合目前商业agent的体感流程
老师：依然询问机构 是上交 华为等 认为有价值

SEAgent框架 计算机软件界面操作领域的agent 专业软件使用agent  自演化
问题是目前少有标注训练集 奖励信号不足 通用模型弱
可以通过试错积累经验   通过视觉模型提供奖励信号  可以先多专家再蒸馏到同模型
技术方法：构建世界状态 成功经验用GRPO 失败经验用负KL散度  加权后成败同时学习
老师问意义 以后的软件都适配诸如MCP  则以后这个框架的用途
个人认为：可以放在手机等移动端 软件又简单 操作相对繁杂 可以通用

AgentTTS 多阶段异构子任务的资源分配  目标是最大性能
即每个子任务可以分配不同模型大小 
个人认为怪怪的 主要是还写了测试时资源分配 ？为什么不是直接使用时
老师认为资源也只有一个模型大小 且是一个线性约束问题 直接按问题复杂度排序 模型从高到低分配即可 并没有真正的智能分配
且实验中的基线方法是什么 基线使用的模型又是什么  且机构是什么 Amazon

SE-Agent(不同于上述)  也是效率优化问题
复杂多步推理轨迹的系统性修正
目前每次尝试的轨迹都是孤立的  应该对多次尝试交叉学习迁移重组
生成初始多个轨迹 然后反思 跨轨迹融合 精炼选择 还有使用评估（按照完成度 质量 效率）  迭代保留精英轨迹 最终形成较高的性能
这个路径搜索可以成为范式  本质就是遗传算法思想
个人认为有价值 和今天的（SWE-debate论文比较像）
老师认为轨迹融合比较困难  但问题很普遍

Agent Lightening 一个LLM与agent框架的中间层框架 支持agent的RL 且目标是解耦和效率
现有RL方法是单轮任务 
可以把任意agent的完整轨迹拆成 状态 动作 奖励 三元组；定义统一API 
可以把模型训练和Agent执行进行解耦 
兼容GRPO等单轮RL算法 扩展到任何任务的agent框架
个人觉得很有意义 【值得持续关注】眼前一亮
老师 问机构 微软Microsoft research  以后甚至会有垂域的agent框架  
以前的训练需要RL且agent完整执行路径
现在就可以解耦 

个人思考 目前埋头开发 都是工程问题  注重一些理论文章  以及高屋建瓴视角的文章的追求


----------------------------------------
2025.8.14

aworld框架  解决多agent因为冗长外部tool和上下文的可靠性
思想 动态监督与干预 具体为：但是依然是双模型 执行与监督 监督的是推理链 工具和约束
实验 在GAIA测试集 第一
个人评价：没有技术细节 只有思路和结果 并没有创新 同质化
这个benchmark是通用问题的数据集 很多模型都在这榜单上  此文章是inclusionAI 蚂蚁金服AI


adaptFlow 工作流优化框架
目前是根据不同任务自动优化workflow
MAML：模型无关的元学习  可以针对新任务快速微调
双层优化稳定收敛
老师问题：在多大的模型做的  怎么微调  比原模型没法微调
并且似乎与MAML不一定有关 没有做针对MAML的消融实验


双智能体框架 把推理和code执行分开  解决性能下降问题
技术方案是学习专家数据 并给出一些奖励

MAGRPO算法 中心化训练 去中心化推理
多agent协作完成多任务
技术问题是组采样 中心化评估 去中心化根据同一优势信号独立执行PPO更新
实验在文本生成上相比提示类型多模型 增加推理质量和速度 训练后高效并行


老师综合评价：目前的文章灌水太多
聊研二学生秋招问题  目前秋招很早 大模型岗位很多 竞争者多 混乱求职时代 都是A会 总体更卷
公司面试官很主观  真正懂机器学习的少  没有客观的agent评价体系  大家方向都跟LLM沾边
手撕 多头注意力等  建议先拿保底工作  老师认为第一份工作先大厂 然后做得好  两年一跳槽是必要的  
老师认为明年模型能力提高之后 很多盲目的方法研究就会暴露短板  老师建议坚持有意义的文章




